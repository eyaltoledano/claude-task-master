{
  "models": {
    "main": {
      "provider": "cursor",
      "modelId": "cursor",
      "maxTokens": 100000,
      "temperature": 0.2
    },
    "research": {
      "provider": "cursor",
      "modelId": "cursor",
      "maxTokens": 100000,
      "temperature": 0.1
    },
    "fallback": {
      "provider": "cursor",
      "modelId": "cursor",
      "maxTokens": 100000,
      "temperature": 0.2
    }
  },
  "global": {
    "logLevel": "info",
    "debug": false,
    "defaultSubtasks": 5,
    "defaultPriority": "medium",
    "projectName": "Taskmaster",
    "ollamaBaseUrl": "http://localhost:11434/api",
    "azureOpenaiBaseUrl": "https://your-endpoint.openai.azure.com/"
  }
}