---
description: Guidelines for delegated llm calls.
globs: **/*
alwaysApply: true
trigger: always_on
---
# How to Handle agent_llm Interactions

The `agent_llm` tool is used for managing delegated LLM calls between the Taskmaster server and the agent (you). When a Taskmaster tool (like `parse_prd`, `analyze_project_complexity`, `expand_task`, `expand_all`, `update`, `update_task`, `update_subtask`, `add_task`, `research`, `scope-up-task`, `scope-down-task`) requires an LLM call, Taskmaster delegates this call to the agent (you) using the `agent_llm` mechanism.

## File Path Rules

- **For task-related operations** (parse_prd, expand_task, update_task, add_task, etc.): Always set the `file` parameter to `.taskmaster/tasks/tasks.json` unless the user explicitly specifies a different path.

- **For report operations** (complexity_report): Always set the `file` parameter to `.taskmaster/reports/task-complexity-report.json` unless the user explicitly specifies a different path.

- **General rule**: When calling ANY Taskmaster tool that has a `file` parameter (whether required or optional), always fill it with the appropriate default value based on the tool's description:
  - If the tool description specifies a default value, use that exact default value
  - If no default is specified but the tool deals with tasks, use `.taskmaster/tasks/tasks.json`
  - If no default is specified but the tool deals with reports, use the appropriate report file path

- **Never omit the `file` parameter** when it exists in a tool's schema, even if it's marked as optional. Omitting this parameter can cause issues with file operations, particularly on Windows systems.

## 1. Receiving a Delegated LLM Call

When a Taskmaster tool needs an LLM response, it will return a pending-interaction URI as its result. This result will contain `isAgentLLMPendingInteraction: true` and a `details` object.

The `details` object will include:

- **type**: `"agent_llm"`
- **interactionId**: A unique ID for this specific LLM interaction (e.g., `"e1df3789-1cea-403a-a114-90adcc4cd155"`). You must use this ID when responding.
- **llmRequestForAgent**: This object contains the parameters for the LLM call you need to make:
  - **originalCommand**: The Taskmaster command that initiated this delegation (e.g., `"parse-prd"`).
  - **role**: The AI role for the LLM call (e.g., `"main"`, `"research"`).
  - **serviceType**: The type of LLM service requested (e.g., `"generateObject"`, `"generateText"`, `"streamText"`).
  - **requestParameters**: The actual parameters for the LLM call, such as `messages` (for chat models), `modelId`, `schema` (if serviceType is `generateObject`), etc.

## 2. Processing the Delegated Call (Your Action)

Upon receiving a pending-interaction with `llmRequestForAgent`, you (the agent) are expected to perform the LLM call as specified in the `requestParameters`.

- **Which LLM to Use**: When processing a delegated LLM call, always use the LLM model or environment that is currently running the agent (i.e., the built-in or default LLM). Do not attempt to call external LLM APIs or services unless explicitly instructed in the llmRequestForAgent. If a modelId or other LLM parameters are provided, use them only if they match the agent's available models; otherwise, proceed with the agent's default LLM.

## 3. Submitting the LLM Result to Taskmaster

After performing the LLM call (or determining it cannot be performed due to an error), you must invoke the "agent_llm" tool to send the result back to Taskmaster.

Your arguments for the `agent_llm` tool must include:

- **projectRoot**: The current project root directory (e.g., `"f:/path/to/your/app"`).
- **interactionId**: The interactionId received in the pending-interaction.
- **agentLLMResponse**: An object containing the outcome of the LLM call:
  - **status**: Set to `"success"` if the LLM call was successful, or `"error"` if it failed.
  - **data**: If status is `"success"`, this field should contain the actual LLM response.
  - **errorDetails**: If status is `"error"`, this field should contain details about the error, including a message and optionally a code.

## Important Workflow Notes
**Avoid redundant `get_tasks` calls:** Do not call `get_tasks` before `expand_all` in delegation mode, as `expand_all` already submits delegated task IDs for expansion.
**Note on `research`:** When performing research for a specific task, always fill the `saveToTask` parameter unless the user explicitly requests otherwise.
**Do not make assumptions on the tag parameter:** If you are unaware of the current tag get it with the 'list_tags' tool.

The project is already initialized.