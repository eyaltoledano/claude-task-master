# TaskMaster 并发性能分析报告

## 📊 当前架构概述

TaskMaster目前使用**基于文件的存储系统**，所有数据存储在JSON文件中：

### 🗂️ 数据存储结构
```
projects/
├── {project-id}/
│   └── .taskmaster/
│       ├── tasks/
│       │   └── tasks.json          # 主要任务数据
│       ├── config.json             # 项目配置
│       ├── state.json              # 项目状态
│       └── reports/
│           └── task-complexity-report.json
```

## 🔒 并发控制机制

### 1. 文件锁管理器 (FileLockManager)

**位置**: `server/utils/file-lock-manager.js`

**特性**:
- ✅ **内存级文件锁**: 基于Map的锁管理
- ✅ **请求队列**: 支持锁等待队列（最大10个）
- ✅ **超时机制**: 默认30秒锁超时
- ✅ **锁状态监控**: 可查询锁状态

**限制**:
- ❌ **单进程限制**: 只在单个Node.js进程内有效
- ❌ **无跨服务器锁**: 多实例部署时无法协调
- ❌ **内存丢失**: 进程重启后锁信息丢失

### 2. 文件锁中间件

**位置**: `server/middleware/file-lock.js`

**策略**:
```javascript
// 读操作策略
skipLockForRead: true    // GET请求跳过锁定

// 写操作策略  
skipLockForRead: false   // 任务操作需要锁定

// 超时配置
timeout: 30000          // 普通操作30秒
timeout: 60000          // PRD解析60秒
```

## 📈 并发性能评估

### 🟢 优势

1. **读操作并发性好**
   - GET请求无锁限制
   - 多个用户可同时查看任务
   - 响应速度快

2. **写操作安全性高**
   - 文件级锁定防止数据竞争
   - 队列机制保证操作顺序
   - 超时机制防止死锁

3. **简单可靠**
   - 无需外部数据库
   - 部署简单
   - 数据可直接查看

### 🔴 瓶颈和限制

#### 1. **写操作串行化**
```
用户A: 添加任务 → 获取锁 → 写入文件 → 释放锁
用户B: 更新任务 → 等待锁   → 写入文件 → 释放锁  
用户C: 删除任务 → 等待锁   → 写入文件 → 释放锁
```
**影响**: 同一项目的所有写操作必须串行执行

#### 2. **文件I/O瓶颈**
- 每次操作都需要读取整个tasks.json文件
- 大型项目（>1000任务）文件读写耗时增加
- 磁盘I/O成为性能瓶颈

#### 3. **内存使用**
- 每次操作加载完整任务数据到内存
- 多项目并发时内存占用高
- 无缓存机制，重复读取文件

#### 4. **扩展性限制**
- 单进程锁管理，无法水平扩展
- 多实例部署时数据不一致
- 无法支持真正的高并发

## 🧪 性能测试建议

### 测试场景

1. **读并发测试**
   ```bash
   # 100个并发GET请求
   ab -n 1000 -c 100 http://localhost:3000/api/projects/test/tasks
   ```

2. **写并发测试**
   ```bash
   # 10个并发POST请求（受锁限制）
   ab -n 100 -c 10 -p task.json http://localhost:3000/api/projects/test/tasks
   ```

3. **混合负载测试**
   ```bash
   # 90%读 + 10%写的混合负载
   wrk -t12 -c400 -d30s --script=mixed_load.lua http://localhost:3000
   ```

### 预期性能指标

| 操作类型 | 并发数 | 预期QPS | 响应时间 |
|---------|--------|---------|----------|
| 读操作 | 100 | 500-1000 | <100ms |
| 写操作 | 10 | 10-50 | 200-500ms |
| 混合负载 | 50 | 200-400 | <200ms |

## 🚀 性能优化建议

### 短期优化（保持文件存储）

1. **添加缓存层**
   ```javascript
   // Redis缓存热点数据
   const cache = new Redis();
   
   // 缓存任务列表
   await cache.setex(`tasks:${projectId}`, 300, JSON.stringify(tasks));
   ```

2. **优化文件读写**
   ```javascript
   // 增量更新而非全量重写
   // 使用流式读写大文件
   // 压缩JSON数据
   ```

3. **细化锁粒度**
   ```javascript
   // 任务级锁而非文件级锁
   const lockKey = `task:${projectId}:${taskId}`;
   ```

### 中期优化（混合存储）

1. **热数据内存化**
   - 活跃项目数据保存在内存
   - 定期持久化到文件
   - LRU策略管理内存

2. **读写分离**
   - 读操作从缓存获取
   - 写操作异步持久化
   - 事件驱动更新缓存

### 长期优化（数据库存储）

1. **迁移到数据库**
   ```sql
   -- PostgreSQL示例
   CREATE TABLE tasks (
     id SERIAL PRIMARY KEY,
     project_id VARCHAR(255),
     title TEXT,
     description TEXT,
     status VARCHAR(50),
     created_at TIMESTAMP,
     updated_at TIMESTAMP
   );
   
   CREATE INDEX idx_tasks_project_id ON tasks(project_id);
   ```

2. **分布式锁**
   ```javascript
   // Redis分布式锁
   const lock = await redlock.acquire([`lock:project:${projectId}`], 30000);
   ```

3. **水平扩展**
   - 多实例部署
   - 负载均衡
   - 数据库连接池

## 📊 并发能力评估

### 当前能力

| 指标 | 单项目 | 多项目 | 说明 |
|------|--------|--------|------|
| 读并发 | 无限制 | 无限制 | 受CPU/内存限制 |
| 写并发 | 1 | N | 每项目最多1个写操作 |
| 响应时间 | 50-200ms | 100-500ms | 随项目大小增加 |
| 内存使用 | 10-100MB | 100MB-1GB | 随任务数量增加 |

### 瓶颈分析

1. **最大并发写操作**: 项目数量（每项目1个）
2. **单项目写QPS**: 约10-50 QPS
3. **文件大小限制**: 建议<10MB（约5000任务）
4. **内存限制**: 建议<2GB总内存使用

## 🎯 结论和建议

### 适用场景
- ✅ **小团队使用**（<10人）
- ✅ **中小型项目**（<1000任务）
- ✅ **读多写少**的场景
- ✅ **单实例部署**

### 不适用场景
- ❌ **大团队协作**（>20人）
- ❌ **大型项目**（>5000任务）
- ❌ **高频写操作**
- ❌ **多实例部署**

### 升级路径
1. **立即**: 添加Redis缓存
2. **3个月内**: 实现读写分离
3. **6个月内**: 迁移到PostgreSQL
4. **1年内**: 支持分布式部署

当前的文件存储方案适合中小规模使用，但如需支持大规模并发，建议按照升级路径逐步优化。
